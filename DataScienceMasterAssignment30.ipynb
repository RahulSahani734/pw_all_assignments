{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXaXec0Mpzhn"
   },
   "source": [
    "### Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with\n",
    "### an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbOGQzo5qLng"
   },
   "source": [
    "The Probability Mass Function (PMF) and Probability Density Function (PDF) are both mathematical concepts used in probability and statistics to describe the distribution of random variables. They provide information about the likelihood of different outcomes occurring for discrete and continuous random variables, respectively.\n",
    "\n",
    "**Probability Mass Function (PMF):**\n",
    "The PMF is used for discrete random variables. It gives the probability of a specific outcome or value occurring. In other words, it defines the probability distribution over all possible values of the random variable.\n",
    "\n",
    "Mathematically, for a discrete random variable \"X,\" the PMF is denoted as \\(P(X = x)\\) or \\(p(x)\\), and it satisfies the following properties:\n",
    "1. \\(0 \\leq P(X = x) \\leq 1\\) for all possible values of \\(x\\).\n",
    "2. The sum of probabilities over all possible values of \\(x\\) is equal to 1.\n",
    "\n",
    "**Probability Density Function (PDF):**\n",
    "The PDF is used for continuous random variables. It provides the relative likelihood of a random variable falling within a particular range of values. Unlike the PMF, which directly gives probabilities, the PDF gives the probability density per unit interval on the x-axis.\n",
    "\n",
    "Mathematically, for a continuous random variable \"X,\" the PDF is denoted as \\(f(x)\\), and it satisfies the following properties:\n",
    "1. \\(f(x) \\geq 0\\) for all \\(x\\).\n",
    "2. The area under the PDF curve over a specific range on the x-axis represents the probability of the random variable falling within that range.\n",
    "3. The total area under the entire PDF curve is equal to 1.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Let's consider a simple example of rolling a fair six-sided die.\n",
    "\n",
    "1. **Probability Mass Function (PMF):**\n",
    "   The PMF for rolling a fair six-sided die can be represented as:\n",
    "   \\[ P(X = x) = \\frac{1}{6} \\quad \\text{for } x = 1, 2, 3, 4, 5, 6 \\]\n",
    "\n",
    "   In this case, the PMF gives the probability of getting each specific value when rolling the die.\n",
    "\n",
    "2. **Probability Density Function (PDF):**\n",
    "   Now, let's consider the example of the height of individuals in a population. Suppose the heights are normally distributed with a mean of 170 cm and a standard deviation of 10 cm. The PDF for this distribution can be represented as:\n",
    "   \\[ f(x) = \\frac{1}{\\sqrt{2\\pi} \\cdot 10} \\cdot e^{-\\frac{(x - 170)^2}{2 \\cdot 10^2}} \\]\n",
    "\n",
    "   In this case, the PDF gives the relative likelihood of an individual's height falling within a specific range of values around the mean.\n",
    "\n",
    "In summary, the PMF is used for discrete random variables and gives the probabilities of specific outcomes, while the PDF is used for continuous random variables and gives the relative likelihood of values falling within specific intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8NULyhPjppJy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AjL-W3J8qQSS"
   },
   "source": [
    "### Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBMiIcHrqQ5Q"
   },
   "source": [
    "I see that you have repeated the question, but no worries! I'll provide another explanation and example for better clarity.\n",
    "\n",
    "The Cumulative Distribution Function (CDF) is a fundamental concept in probability and statistics that describes the cumulative probability of a random variable taking on a value less than or equal to a specific value. In essence, it gives you the probability that a random variable is less than or equal to a certain value.\n",
    "\n",
    "Mathematically, for a random variable \"X,\" the CDF is denoted as \\(F(x)\\), and it is defined as:\n",
    "\n",
    "\\[ F(x) = P(X \\leq x) \\]\n",
    "\n",
    "Here's an example to help illustrate the concept:\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Suppose we have a continuous random variable \"X\" representing the height of individuals in a certain population. Let's say that the heights are normally distributed with a mean (\\(\\mu\\)) of 170 cm and a standard deviation (\\(\\sigma\\)) of 10 cm.\n",
    "\n",
    "The CDF for this normal distribution can be calculated using the formula for the standard normal distribution (a special case of the normal distribution with \\(\\mu = 0\\) and \\(\\sigma = 1\\)):\n",
    "\n",
    "\\[ F(x) = \\frac{1}{2} \\left(1 + \\text{erf}\\left(\\frac{x - \\mu}{\\sigma \\sqrt{2}}\\right)\\right) \\]\n",
    "\n",
    "In this formula, \"erf\" represents the error function, and \\(x\\) is the value for which we want to calculate the cumulative probability.\n",
    "\n",
    "Let's say we want to find the probability that an individual's height is less than or equal to 180 cm:\n",
    "\n",
    "\\[ P(X \\leq 180) = F(180) = \\frac{1}{2} \\left(1 + \\text{erf}\\left(\\frac{180 - 170}{10 \\sqrt{2}}\\right)\\right) \\]\n",
    "\n",
    "Using a calculator or software, you can calculate this probability, which would represent the cumulative probability of an individual's height being less than or equal to 180 cm.\n",
    "\n",
    "**Why CDF is Used:**\n",
    "\n",
    "The Cumulative Distribution Function is used for various reasons:\n",
    "\n",
    "1. **Probability Calculation:** CDF gives you the probability of a random variable falling within a certain range, making it useful for probability calculations.\n",
    "2. **Quantiles and Percentiles:** It helps determine percentiles, which represent specific points below which a certain percentage of the data falls.\n",
    "3. **Comparisons:** CDFs of different distributions or datasets can be compared to assess differences in their distributions.\n",
    "4. **Graphical Representation:** CDF graphs provide insights into the overall distribution and its characteristics.\n",
    "\n",
    "In summary, the CDF provides a comprehensive way to understand the cumulative probabilities of a random variable, making it a fundamental tool in probability theory and statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JuwmNbDaqezZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYjAVCHDqfGn"
   },
   "source": [
    "### Q3: What are some examples of situations where the normal distribution might be used as a model?\n",
    "Explain how the parameters of the normal distribution relate to the shape of the distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cn3E2zAUqk82"
   },
   "source": [
    "The normal distribution, also known as the Gaussian distribution, is one of the most widely used probability distributions in statistics due to its versatility and applicability in various real-world scenarios. Here are some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "1. **Height of Individuals:** The heights of a population tend to follow a normal distribution. The mean and standard deviation of the distribution can vary among different populations, but in general, heights cluster around a central value with most individuals falling within a certain range.\n",
    "\n",
    "2. **Measurement Errors:** Errors in measurements, such as readings from instruments, often follow a normal distribution. This makes the normal distribution useful for modeling the variability in measurement data.\n",
    "\n",
    "3. **IQ Scores:** IQ scores are often assumed to be normally distributed, with a mean of 100 and a standard deviation of 15. This assumption helps in comparing individuals' intelligence scores.\n",
    "\n",
    "4. **Test Scores:** Scores on standardized tests, like SAT or GRE, are often modeled using a normal distribution, allowing educators to set percentiles and evaluate performance.\n",
    "\n",
    "5. **Financial Markets:** Asset prices and returns in financial markets are often modeled using a normal distribution in many financial models, although real market data might deviate from this assumption due to market volatility.\n",
    "\n",
    "6. **Natural Phenomena:** Many natural phenomena, such as the distribution of birth weights, errors in biological measurements, and variation in chemical reactions, can be approximated by the normal distribution.\n",
    "\n",
    "**Parameters of the Normal Distribution:**\n",
    "\n",
    "The normal distribution is characterized by two parameters: the mean (\\(\\mu\\)) and the standard deviation (\\(\\sigma\\)).\n",
    "\n",
    "1. **Mean (\\(\\mu\\)):** The mean determines the center of the distribution, where the peak or highest point of the curve is located. It is also the average value of the data points. Shifting the mean to the left or right moves the entire distribution along the x-axis.\n",
    "\n",
    "2. **Standard Deviation (\\(\\sigma\\)):** The standard deviation measures the spread or variability of the distribution. A larger standard deviation results in a wider curve, indicating more dispersion of data points. A smaller standard deviation results in a narrower curve, indicating less dispersion.\n",
    "\n",
    "In summary, the normal distribution is used as a model in situations where data cluster around a central value and exhibit a symmetrical bell-shaped pattern. The mean sets the location of the peak, and the standard deviation determines the spread of the distribution. The relationship between these parameters shapes the curve and defines the characteristics of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SGRnPLy_qo3q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8QAaxqHqpPD"
   },
   "source": [
    "### Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal\n",
    "Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMw7868jqx6i"
   },
   "source": [
    "The normal distribution, also known as the Gaussian distribution, is of paramount importance in various fields of statistics, science, and engineering due to its remarkable properties and its ability to model a wide range of natural phenomena. Its significance lies in its pervasive presence in real-world data and its role in making statistical analyses and predictions more accurate and tractable. Here are some key reasons why the normal distribution is important:\n",
    "\n",
    "**1. Central Limit Theorem (CLT):** The normal distribution is central to the Central Limit Theorem, which states that the sum (or average) of a large number of independent, identically distributed random variables tends to follow a normal distribution regardless of the underlying distribution of those variables. This property makes the normal distribution a natural choice to model aggregates of random events, leading to its applicability in many real-world scenarios.\n",
    "\n",
    "**2. Inference and Hypothesis Testing:** Many statistical inference methods, such as confidence intervals and hypothesis tests, are based on the properties of the normal distribution. The normal distribution's known characteristics simplify the calculations and allow for meaningful interpretations.\n",
    "\n",
    "**3. Approximation:** The normal distribution can serve as an approximation for other distributions. When sample sizes are sufficiently large, various distributions tend to behave more like a normal distribution, which makes statistical analyses more straightforward.\n",
    "\n",
    "**4. Data Transformation:** In cases where data doesn't follow a normal distribution, transforming the data using logarithms or other methods can often make it more normal. This is important for enabling accurate statistical analyses and modeling.\n",
    "\n",
    "**5. Predictive Models:** Many statistical and machine learning models, such as linear regression and neural networks, assume that errors follow a normal distribution. This assumption allows for accurate predictions and confidence intervals.\n",
    "\n",
    "**Real-Life Examples of Normal Distribution:**\n",
    "\n",
    "1. **Height of Individuals:** Human heights in a population often follow a normal distribution. Most people cluster around the average height, with fewer individuals at both extremes.\n",
    "\n",
    "2. **Exam Scores:** The scores on standardized tests, like the SAT, GRE, or IQ tests, often exhibit a normal distribution. The majority of test-takers score near the mean, and fewer scores are obtained at the extremes.\n",
    "\n",
    "3. **Weight of Newborns:** The birth weights of newborn babies tend to follow a normal distribution. Most babies are born with weights close to the mean birth weight, with fewer babies having very high or very low weights.\n",
    "\n",
    "4. **Measurement Errors:** Errors in measurements, such as instrument readings or laboratory measurements, often follow a normal distribution. This assumption is used to quantify measurement uncertainty.\n",
    "\n",
    "5. **Stock Market Returns:** Although not perfectly normal, stock market returns exhibit some similarity to a normal distribution. This allows for the use of normal distribution-based models in financial analyses.\n",
    "\n",
    "6. **Reaction Times:** Human reaction times to stimuli, such as pressing a button in response to a visual cue, often follow a normal distribution. Most reaction times cluster around a central value.\n",
    "\n",
    "These examples illustrate the prevalence of the normal distribution in various aspects of our lives and highlight its importance in understanding and modeling real-world phenomena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6J7zZdIaqyyQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTQQvFdyqzCJ"
   },
   "source": [
    "### Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli\n",
    "### Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mkvmcoxyq3mK"
   },
   "source": [
    "The Bernoulli distribution is a discrete probability distribution that models a random experiment with two possible outcomes: success (usually denoted by 1) and failure (usually denoted by 0). The distribution is named after the Swiss mathematician Jacob Bernoulli, who introduced it in the 18th century. The Bernoulli distribution is characterized by a single parameter, often denoted as \"p,\" which represents the probability of success in a single trial.\n",
    "\n",
    "Mathematically, the probability mass function (PMF) of the Bernoulli distribution is given by:\n",
    "\n",
    "P(X = x) = p^x * (1 - p)^(1 - x),\n",
    "\n",
    "where:\n",
    "- P(X = x) is the probability that the random variable X takes the value x (either 0 or 1).\n",
    "- p is the probability of success (x = 1).\n",
    "- 1 - p is the probability of failure (x = 0).\n",
    "\n",
    "An example of the Bernoulli distribution is flipping a biased coin, where the coin has a probability \"p\" of landing heads (success) and a probability \"1 - p\" of landing tails (failure).\n",
    "\n",
    "Now, let's discuss the difference between the Bernoulli distribution and the Binomial distribution:\n",
    "\n",
    "1. **Bernoulli Distribution**:\n",
    "   - Models a single trial with two possible outcomes: success (1) or failure (0).\n",
    "   - Only has one parameter: the probability of success \"p.\"\n",
    "   - Mathematically represented by P(X = x) = p^x * (1 - p)^(1 - x) for x = 0 or 1.\n",
    "\n",
    "2. **Binomial Distribution**:\n",
    "   - Models a series of independent and identical Bernoulli trials.\n",
    "   - Has two parameters: the number of trials \"n\" and the probability of success \"p.\"\n",
    "   - Represents the probability of getting exactly \"k\" successes out of \"n\" trials.\n",
    "   - Mathematically represented by the PMF: P(X = k) = (n choose k) * p^k * (1 - p)^(n - k), where \"n choose k\" is the binomial coefficient.\n",
    "\n",
    "In summary, the Bernoulli distribution deals with a single trial with two outcomes, while the Binomial distribution deals with multiple trials, each having two outcomes, and calculates the probability of a specific number of successes occurring in those trials. The Binomial distribution can be thought of as a sum of independent and identically distributed Bernoulli random variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUkcaSfyrKo1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9Yv68uVrLDJ"
   },
   "source": [
    "### Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset\n",
    "### is normally distributed, what is the probability that a randomly selected observation will be greater\n",
    "### than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iu9bG2FfrLrf"
   },
   "source": [
    "To calculate the probability that a randomly selected observation from a normally distributed dataset with a mean of 50 and a standard deviation of 10 will be greater than 60, we can use the standard normal distribution (z) and the z-score formula. The z-score formula is:\n",
    "\n",
    "z = (x - μ) / σ,\n",
    "\n",
    "where:\n",
    "- z is the z-score,\n",
    "- x is the value we're interested in (60 in this case),\n",
    "- μ is the mean of the distribution (50 in this case),\n",
    "- σ is the standard deviation of the distribution (10 in this case).\n",
    "\n",
    "Let's calculate the z-score:\n",
    "\n",
    "z = (60 - 50) / 10 = 1.0.\n",
    "\n",
    "Now, we need to find the probability associated with the z-score of 1.0. This can be done using a standard normal distribution table or a calculator. The probability that a randomly selected observation will be greater than 60 can be found by looking up the cumulative probability of the standard normal distribution for a z-score of 1.0.\n",
    "\n",
    "Using a standard normal distribution table or calculator, we find that the cumulative probability for a z-score of 1.0 is approximately 0.8413.\n",
    "\n",
    "Therefore, the probability that a randomly selected observation from the given dataset will be greater than 60 is approximately 0.8413, or 84.13%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j406u0iirVL1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cves9Wz6rWrE"
   },
   "source": [
    "### Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1wn0RdYrXX9"
   },
   "source": [
    "The uniform distribution is a probability distribution that describes a situation in which all outcomes within a given range are equally likely. In other words, each possible outcome has the same probability of occurring, resulting in a constant probability density function over the entire range.\n",
    "\n",
    "Mathematically, the probability density function (PDF) of a continuous uniform distribution on the interval [a, b] is given by:\n",
    "\n",
    "f(x) = 1 / (b - a) for a ≤ x ≤ b,\n",
    "       0            otherwise.\n",
    "\n",
    "Here, \"a\" and \"b\" represent the lower and upper bounds of the interval, respectively.\n",
    "\n",
    "An example of a uniform distribution is rolling a fair six-sided die. In this case, the possible outcomes are the numbers 1 through 6, and each of these outcomes is equally likely to occur. The distribution is uniform because the probability of getting any specific outcome is 1/6, and this probability is the same for all the possible outcomes.\n",
    "\n",
    "Let's consider another example:\n",
    "\n",
    "**Example: Random Number Generation**\n",
    "Suppose you have a computer program that generates random numbers between 0 and 1. If the random number generator is truly uniform, then any value within the interval [0, 1] has an equal chance of being generated. This means that the probability of generating a number between 0 and 0.2 is the same as generating a number between 0.4 and 0.6 or any other subinterval of equal length within [0, 1].\n",
    "\n",
    "This concept is also used in various applications such as simulations, cryptography, and Monte Carlo methods, where the goal is to generate random numbers that are uniformly distributed to model different scenarios or perform probabilistic computations.\n",
    "\n",
    "In summary, a uniform distribution is characterized by all outcomes having equal probabilities within a specific interval. It's often visualized as a flat, constant graph over the range of possible values, indicating the equal likelihood of any value occurring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yApZRcvGrZuk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRQpeW_LraFM"
   },
   "source": [
    "### Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_B2tyRZrenK"
   },
   "source": [
    "The z-score, also known as the standard score, is a statistical measure that quantifies the number of standard deviations a data point is away from the mean of a dataset. It's a way to standardize and compare values from different distributions by expressing them in terms of a common scale.\n",
    "\n",
    "The formula for calculating the z-score of a data point \"x\" in a dataset with mean \"μ\" and standard deviation \"σ\" is:\n",
    "\n",
    "z = (x - μ) / σ.\n",
    "\n",
    "The z-score tells us how far a particular data point deviates from the mean in terms of the standard deviation. A positive z-score indicates that the data point is above the mean, while a negative z-score indicates that it's below the mean.\n",
    "\n",
    "Importance of the z-score:\n",
    "\n",
    "1. **Standardization**: The z-score allows us to standardize data from different distributions into a common scale. This is particularly useful when comparing data points from different datasets with varying means and standard deviations. It helps in understanding the relative position of a data point within its distribution.\n",
    "\n",
    "2. **Identifying Outliers**: Z-scores can help identify outliers, which are data points that significantly deviate from the mean. Outliers typically have z-scores with magnitudes much larger (in absolute value) than a certain threshold, indicating their extreme position in the distribution.\n",
    "\n",
    "3. **Probability Analysis**: The z-score is used in conjunction with the standard normal distribution (z-distribution) to calculate probabilities associated with specific values. This is crucial in hypothesis testing, confidence interval estimation, and determining critical values for significance tests.\n",
    "\n",
    "4. **Comparing Values**: Z-scores allow us to compare values from different datasets. For example, if you have test scores from two different classes with different means and standard deviations, you can use z-scores to understand how a student's performance in one class compares to their performance in the other class.\n",
    "\n",
    "5. **Data Transformation**: Z-scores are often used to transform data in ways that help in data analysis. Transforming data into z-scores can make it easier to apply statistical techniques or visualize patterns in the data.\n",
    "\n",
    "In summary, the z-score is a powerful statistical tool that standardizes data, facilitates comparison and analysis, identifies outliers, and enables probability calculations. It's a fundamental concept in statistics with widespread applications in various fields such as research, finance, quality control, and data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nGaIBgJkr7ZN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uf2WiiLIr80p"
   },
   "source": [
    "###  Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snheZTcur-Fi"
   },
   "source": [
    "The central limit theorem (CLT) is a statistical theorem that states that, given certain assumptions, the mean of a sufficiently large number of iterates of independent random variables, each with a well-defined expected value and well-defined variance, will be approximately normally distributed, regardless of the underlying distribution of the original random variables.\n",
    "\n",
    "The CLT is a fundamental theorem in probability theory because it implies that many probabilistic and statistical methods that work for normally distributed data can be applied to data from other distributions. For example, the CLT is used in hypothesis testing, confidence intervals, and regression analysis.\n",
    "\n",
    "The CLT has four main assumptions:\n",
    "\n",
    "1. The samples must be randomly drawn from the population.\n",
    "2. The samples must be independent of each other.\n",
    "3. The population must have a finite mean and variance.\n",
    "4. The sample size must be large enough.\n",
    "\n",
    "The CLT is a very powerful tool, but it is important to remember that it only applies under certain conditions. If these conditions are not met, the CLT may not be accurate.\n",
    "\n",
    "The significance of the CLT is that it allows us to make inferences about a population based on a sample. For example, if we know that the CLT applies to a population, then we can be confident that the sampling distribution of the mean will be approximately normally distributed, even if the population distribution is not normally distributed. This means that we can use the normal distribution to calculate probabilities and confidence intervals for the population mean.\n",
    "\n",
    "The CLT is also used in many other statistical procedures, such as hypothesis testing and regression analysis. In general, the CLT can be used whenever we want to make inferences about a population based on a sample.\n",
    "\n",
    "Here are some examples of how the CLT is used in practice:\n",
    "\n",
    "* A pharmaceutical company wants to test the effectiveness of a new drug. They randomly select 100 people and give them the drug. They then measure the blood pressure of each person before and after taking the drug. The CLT can be used to calculate the probability that the mean blood pressure of the people who took the drug is lower than the mean blood pressure of the people who did not take the drug.\n",
    "* A financial analyst wants to estimate the average return on investment for a particular stock. They randomly select 100 days and look at the stock price on those days. The CLT can be used to calculate a confidence interval for the average return on investment.\n",
    "* A researcher wants to study the relationship between height and weight in children. They randomly select 100 children and measure their height and weight. The CLT can be used to estimate the slope of the regression line that predicts weight from height.\n",
    "\n",
    "The CLT is a powerful tool that is used in many different areas of statistics. It is important to understand the assumptions of the CLT and to make sure that they are met in order to ensure the accuracy of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PDhMwcJMt2Ha"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4capDEvyt2do"
   },
   "source": [
    "### Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0g1AhVet5ZS"
   },
   "source": [
    "The central limit theorem (CLT) states that the sampling distribution of the mean of any independent and identically distributed (i.i.d.) random variable will be approximately normally distributed, regardless of the shape of the population distribution, as the sample size increases.\n",
    "\n",
    "The CLT has four assumptions:\n",
    "\n",
    "1. The samples must be randomly drawn from the population.\n",
    "2. The samples must be independent of each other.\n",
    "3. The population must have a finite mean and variance.\n",
    "4. The sample size must be large enough.\n",
    "\n",
    "The first assumption is important because it ensures that all samples have an equal chance of being selected. The second assumption is important because it ensures that the samples are not correlated with each other. The third assumption is important because it ensures that the CLT will work correctly. The fourth assumption is important because it ensures that the sampling distribution of the mean will be approximately normal.\n",
    "\n",
    "The CLT is a powerful tool that can be used to make inferences about a population based on a sample. However, it is important to remember that the CLT only applies under certain conditions. If these conditions are not met, the CLT may not be accurate.\n",
    "\n",
    "Here are some additional details about each of the assumptions of the CLT:\n",
    "\n",
    "* **Random sampling:** This means that each member of the population has an equal chance of being selected for the sample. This can be done by using a random number generator or by selecting samples without replacement.\n",
    "* **Independent samples:** This means that the selection of one sample does not affect the selection of any other sample. This can be achieved by drawing samples from different parts of the population or by using a random number generator to select samples without replacement.\n",
    "* **Finite mean and variance:** This means that the population has a finite mean and variance. If the population mean or variance is infinite, the CLT will not apply.\n",
    "* **Large enough sample size:** The sample size must be large enough for the CLT to work correctly. The exact size of the sample size required depends on the shape of the population distribution.\n",
    "\n",
    "In general, the CLT is a very robust theorem and it can be applied to a wide variety of populations. However, it is important to be aware of the assumptions of the CLT and to make sure that they are met in order to ensure the accuracy of the results."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
